{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXdwC3aUxbvC"
   },
   "source": [
    "# [hy] 네이버 카페_레몬테라스 크롤러 with 키워드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRUx_2VAxbvI"
   },
   "source": [
    "### install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68p76R41xbvI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install selenium==4.1.0\n",
    "# %pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-8bgYvtxbvK"
   },
   "source": [
    "### 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgiXhpNHxbvL"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException\n",
    "import urllib.request\n",
    "import random\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjNAJxJcxbvN"
   },
   "source": [
    "### 검색 키워드 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMN-sjl42uVp"
   },
   "outputs": [],
   "source": [
    "sample = ['엽떡', '신전']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyqSatv5xbvM"
   },
   "source": [
    "### 레몬테라스 로그인\n",
    "##### 크롬드라이버 위치 변경 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9Md74TAxbvM"
   },
   "outputs": [],
   "source": [
    "# 크롬 드라이버 제어\n",
    "driver = webdriver.Chrome() #현재 컴퓨터 크롬드라이버 위치로 변경\n",
    "\n",
    "# 네이버 로그인 화면 이동\n",
    "login_url = 'https://nid.naver.com/nidlogin.login'\n",
    "driver.get(login_url)\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# 아이디& 비밀번호 입력\n",
    "my_id = '본인id' # \"id\" 대신에 자신의 네이버 아이디 입력\n",
    "my_pw = '본인password' # \"password\" 대신에 자신의 네이버 비밀번호 입력\n",
    "\n",
    "# 로그인 id, pw 입력\n",
    "# 네이버에 로그인 할 경우 'send_keys()' 함수가 아니라 'execute_script()' 함수를 사용\n",
    "driver.execute_script(\"document.getElementsByName('id')[0].value = \\'\" + my_id + \"\\'\")\n",
    "driver.execute_script(\"document.getElementsByName('pw')[0].value = \\'\" + my_pw + \"\\'\")\n",
    "time.sleep(1)\n",
    "\n",
    "# '로그인' 버튼 클릭\n",
    "driver.find_element(By.XPATH, '//*[@id=\"log.login\"]').click()\n",
    "time.sleep(random.uniform(1,1.7))\n",
    "url = 'https://cafe.naver.com/remonterrace' # 크롤링할 카페 url 입력\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Lb7knndxbvO"
   },
   "source": [
    "\n",
    "### 크롤링할 카페 접속 및 원하는 게시판 클릭 & 게시물 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2yRpW84xbvP",
    "outputId": "ca00dec1-ac29-4667-c2f2-8af9ba1dd821",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "6# 제목, 본문, 댓글, 날짜, 검색 키워드, 게시판 이름 - 빈 list 생성\n",
    "titles = []\n",
    "reviews = []\n",
    "comments = []\n",
    "dates = []\n",
    "search_keywords = []\n",
    "board_titles = []\n",
    "\n",
    "# board = ['//*[@id=\"menuLink150\"]'] # 크롤링할 게시판의 xpath 입력; 원하는 게시판 클릭 -> F12 눌러 게시판 선택자 확인 가능\n",
    "\n",
    "# 네이버 카페 접속\n",
    "# 로그인한 네이버 계정이 해당 카페-게시판에 접근 권한이 있어야 합니다.(회원가입 & 등업)\n",
    "# 프레임 전환(네이버 카페는 여러 프레임으로 구성되어서 크롤링할 게시글이 있는 프레임으로 전환해주어야 함)\n",
    "\n",
    "time.sleep(random.uniform(1,1.7))\n",
    "url = 'https://cafe.naver.com/remonterrace' # 크롤링할 카페 url 입력\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "time.sleep(1)\n",
    "for k in sample:\n",
    "    print(k,\"키워드 크롤링 중입니다\")\n",
    "#     for i in board:\n",
    "#         #원하는 게시판 클릭\n",
    "#         driver.find_element_by_xpath('%s'%i).click()\n",
    "#         time.sleep(1)\n",
    "\n",
    "\n",
    "    #검색\n",
    "#     driver.switch_to.default_content()\n",
    "    search_box = driver.find_element(By.XPATH, '//*[@id=\"topLayerQueryInput\"]')\n",
    "    search_box.send_keys(k)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(1)\n",
    "\n",
    "    driver.switch_to.frame('cafe_main')\n",
    "    # 3초간 대기 후 다음 코드 실행\n",
    "    #검색결과 없을 때 다음 게시판으로 넘어가도록\n",
    "\n",
    "#         데이터 수집기간 : 2022년 1월 ~ 2023년 7월(현재) : 19개월\n",
    "    time_box = driver.find_element(By.XPATH, '//*[@id=\"currentSearchDateTop\"]')\n",
    "    time_box.click()\n",
    "    start_time = driver.find_element(By.XPATH, '//*[@id=\"input_1_top\"]')\n",
    "    start_time.click()\n",
    "    time.sleep(0.5)\n",
    "    start_time.send_keys('20220101')\n",
    "    time.sleep(1)\n",
    "    end_time = driver.find_element(By.XPATH, '//*[@id=\"input_2_top\"]')\n",
    "    end_time.click()\n",
    "    time.sleep(0.5)\n",
    "    end_time.send_keys('20240430')\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"btn_set_top\"]').click()\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"main-area\"]/div[1]/div[1]/form/div[4]/button').click()\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        if driver.find_element(By.XPATH, '//*[@id=\"main-area\"]/div[5]/table/tbody/tr/td/div').text.strip() == '등록된 게시글이 없습니다.':\n",
    "            driver.get(url)\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "    except:\n",
    "        print(\"크롤링 시작합미당~\")\n",
    "        pass\n",
    "\n",
    "    #driver.switch_to.frame('cafe_main') # 프레임 전환\n",
    "\n",
    "    # 50개씩 보기\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"listSizeSelectDiv\"]').click()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"listSizeSelectDiv\"]/ul/li[7]/a').click()\n",
    "\n",
    "    #url 가져오기\n",
    "    page_url_list = [a.get_attribute('href') for a in driver.find_elements(By.CSS_SELECTOR, 'a.article')]\n",
    "    first_page = driver.find_element(By.CSS_SELECTOR,'a.on').get_attribute('href')\n",
    "    #페이지 넘기기 검색시 최대 100페이지\n",
    "    for j in range(1,41):\n",
    "        #400개마다 껐다 키기\n",
    "        try:\n",
    "            if j % 8 == 0:\n",
    "                #다음 링크 가져오기\n",
    "                time.sleep(1)\n",
    "                link = first_page[:-1] + str(j)\n",
    "\n",
    "\n",
    "                driver.quit()\n",
    "                driver = webdriver.Chrome() #현재 컴퓨터 크롬드라이버 위치로 변경\n",
    "\n",
    "\n",
    "                ##재로그인\n",
    "                # 네이버 로그인 화면 이동\n",
    "                login_url = 'https://nid.naver.com/nidlogin.login?mode=form&url=https%3A%2F%2Fwww.naver.com'\n",
    "                driver.get(login_url)\n",
    "                driver.implicitly_wait(10)\n",
    "\n",
    "\n",
    "                driver.execute_script(\"document.getElementsByName('id')[0].value = \\'\" + my_id + \"\\'\")\n",
    "                driver.execute_script(\"document.getElementsByName('pw')[0].value = \\'\" + my_pw + \"\\'\")\n",
    "                time.sleep(1)\n",
    "\n",
    "\n",
    "                # '로그인' 버튼 클릭\n",
    "                driver.find_element('id', 'log.login').click()\n",
    "                time.sleep(1)\n",
    "\n",
    "                #다음 링크부터 가져오기\n",
    "                driver.get(link)\n",
    "                driver.switch_to.frame('cafe_main')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            #결과 없을 때 넘어가기\n",
    "        try:\n",
    "            if driver.find_element(By.XPATH, '//*[@id=\"main-area\"]/div[5]/table/tbody/tr/td/div').text.strip() == '등록된 게시글이 없습니다.':\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "        if j == 1:\n",
    "            pass\n",
    "        else:\n",
    "            next_page = first_page[:-1] + str(j)\n",
    "            driver.get(next_page)\n",
    "            time.sleep(1)\n",
    "            driver.switch_to.frame('cafe_main')\n",
    "\n",
    "        page_url_list = [a.get_attribute('href') for a in driver.find_elements(By.CSS_SELECTOR, 'a.article')]\n",
    "\n",
    "\n",
    "        for url in page_url_list:\n",
    "            try:\n",
    "                driver.get(url)\n",
    "                time.sleep(random.uniform(1,1.7))\n",
    "                driver.switch_to.frame('cafe_main')\n",
    "            except :\n",
    "                continue\n",
    "            try:\n",
    "\n",
    "                #게시판 이름 수집\n",
    "                board_title = driver.find_element(By.CSS_SELECTOR, 'div.ArticleTitle').text\n",
    "                board_titles.append(board_title)\n",
    "                title = driver.find_element(By.CSS_SELECTOR, 'h3.title_text').text\n",
    "                titles.append(title)\n",
    "\n",
    "                #날짜 수집\n",
    "                day = driver.find_element(By.CSS_SELECTOR, '#app > div > div > div.ArticleContentBox > div.article_header > div.WriterInfo > div.profile_area > div.article_info > span.date').text\n",
    "                soup = bs(driver.page_source, 'lxml')\n",
    "                isdate = soup.find_all('span',class_='date')\n",
    "                dates.append(isdate)\n",
    "\n",
    "                #키워드 수집\n",
    "                search_keywords.append(k)\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                content = driver.find_element(By.CSS_SELECTOR, 'div.se-module.se-module-text').text\n",
    "                reviews.append(content)\n",
    "            except:\n",
    "                try:\n",
    "                    content = driver.find_element(By.CSS_SELECTOR, 'div.ContentRenderer').text\n",
    "                    reviews.append(content)\n",
    "                except:\n",
    "                    try:\n",
    "                        content = driver.find_element(By.CSS_SELECTOR, 'div.scrap_added').text.strip()\n",
    "                        reviews.append(content)\n",
    "                    except:\n",
    "                        content= [] #게시물 본문이 사진으로만 구성되어있을때\n",
    "                        reviews.append(content)\n",
    "\n",
    "            # 댓글 수집\n",
    "            soup = bs(driver.page_source, 'lxml')\n",
    "            iscomment = soup.find_all('span',class_='text_comment')\n",
    "            if len(iscomment) == 0:\n",
    "                comment = '댓글 없음'\n",
    "\n",
    "            else:\n",
    "                WebDriverWait(driver, 15).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"text_comment\")) )\n",
    "#                 soup = bs(driver.page_source, 'lxml')\n",
    "                iscomment = soup.find_all('span',class_='text_comment')\n",
    "                comment = ''\n",
    "                for i in iscomment:\n",
    "                    comment += i.get_text() + '. '\n",
    "\n",
    "            comments.append(comment)\n",
    "#             comments.append(box)\n",
    "\n",
    "\n",
    "    url = 'https://cafe.naver.com/remonterrace' # 크롤링할 카페 url 입력\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "# # 크롬 창 닫기\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STH_5E_WxbvR"
   },
   "source": [
    "### 클롤링 개수 확인(키워드, 게시판, 제목, 본문, 댓글, 날짜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAiLJTxAxbvR"
   },
   "outputs": [],
   "source": [
    "print(len(search_keywords))\n",
    "print(len(board_titles))\n",
    "print(len(titles))\n",
    "print(len(reviews))\n",
    "print(len(comments))\n",
    "print(len(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Jkv0_NL2uVr"
   },
   "outputs": [],
   "source": [
    "data = {'keyword' : search_keywords,\n",
    "#         'board' : formatted_boards,\n",
    "        'title' : titles,\n",
    "        'body' : reviews,\n",
    "        'comment' : comments,\n",
    "        'date': dates}\n",
    "\n",
    "dataDF = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAfZ4hCSxbvR"
   },
   "source": [
    "### 크롤링 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hM4YBke1xbvS"
   },
   "outputs": [],
   "source": [
    "#날짜 포멧 '2023.03.20.' 위 형태로 포맷\n",
    "import re\n",
    "\n",
    "formatted_dates = []\n",
    "#게시판 제목 포맷\n",
    "formatted_boards = []\n",
    "for board_title in board_titles:\n",
    "    formatted_boards.append(board_title.split(\"\\n\")[0])\n",
    "\n",
    "\n",
    "for date in [str(d[0]) for d in dates]:\n",
    "    date_str = re.search(r'\\d{4}\\.\\d{2}\\.\\d{2}\\.', date).group(0)\n",
    "    formatted_dates.append(date_str)\n",
    "\n",
    "# ===데이터 합치기===\n",
    "\n",
    "data = {'keyword' : search_keywords,\n",
    "        'board' : formatted_boards,\n",
    "        'title' : titles,\n",
    "        'body' : reviews,\n",
    "        'comment' : comments,\n",
    "        'date': formatted_dates}\n",
    "\n",
    "dataDF = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gm18yROrxbvS"
   },
   "source": [
    "### CSV 저장 & 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1eUCgdaxbvT"
   },
   "outputs": [],
   "source": [
    "dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqH5KckAxbvT"
   },
   "outputs": [],
   "source": [
    "dataDF\n",
    "\n",
    "#csv로 저장\n",
    "dataDF.to_csv(\"[hy]대분류이름_담당자.csv\", encoding = \"utf-8-sig\") #파일 이름 변경 필요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph0QRb38xbvT"
   },
   "source": [
    "- 누가 크롤링한 건지 확인할 수 있도록 키워드, 담당자 이름을 꼭 파일명에 넣어주세요!\n",
    "- 어떤 키워드로 검색했을 때 나온 결과인지 알 수 있도록 키워드 꼬옥 넣어주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqRAIC6_pSyu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
