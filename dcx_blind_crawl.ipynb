{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0708d7",
   "metadata": {
    "id": "bc0708d7"
   },
   "source": [
    "## Mas Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9c391",
   "metadata": {
    "id": "b7f9c391"
   },
   "outputs": [],
   "source": [
    "!pip install ipywidgets --upgrade\n",
    "!pip install jupyter --upgrade\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693decb1",
   "metadata": {
    "id": "693decb1"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import urllib.request # URL requests\n",
    "import urllib.parse # URL parsing\n",
    "\n",
    "import requests # HTTP requests\n",
    "from bs4 import BeautifulSoup as bs # HTML parsing\n",
    "\n",
    "from selenium import webdriver # Chromedriver\n",
    "from selenium.webdriver.common.by import By # HTML element 선택\n",
    "from selenium.webdriver.common.keys import Keys # 키보드 키 입력 위함\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities # 크롬 옵션 설정\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException # 예외 처리 위함\n",
    "from selenium.common.exceptions import NoSuchElementException, InvalidSessionIdException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a02b8",
   "metadata": {
    "id": "5b3a02b8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() # 크롬드라이버 객체 생성(초기화)\n",
    "driver.implicitly_wait(3) # 암묵적 대기(3초)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b801e",
   "metadata": {
    "id": "9a1b801e"
   },
   "outputs": [],
   "source": [
    "# 키워드\n",
    "keyword = ['반찬', '식습관']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac1cd2",
   "metadata": {
    "id": "7bac1cd2"
   },
   "outputs": [],
   "source": [
    "# url 폴더 생성\n",
    "if not os.path.exists('url'):\n",
    "    os.makedirs('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ddb01",
   "metadata": {
    "id": "a35ddb01",
    "outputId": "4c3424a4-3cd9-4b4a-b04a-98e86cb73b00"
   },
   "outputs": [],
   "source": [
    "# 키워드 검색후 url 수집\n",
    "for word in keyword:\n",
    "    url_list=[]\n",
    "    date_list=[]\n",
    "    driver.get('https://www.teamblind.com/kr/search/'+word) # '키워드' 검색\n",
    "\n",
    "    # 추천순 버튼 클릭\n",
    "    button = driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div/div[3]/div[2]/span/a')\n",
    "    button.click()\n",
    "\n",
    "    # 최신순 버튼 클릭\n",
    "    button = driver.find_element(By.XPATH, '//*[@id=\"search_sort\"]/a[2]')\n",
    "    button.click()\n",
    "\n",
    "    # 페이지 끝까지 내리기\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(1,1.7))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "\n",
    "        last_height = new_height\n",
    "\n",
    "    # 검색결과 url과 날짜 수집\n",
    "    url_elements = driver.find_elements(By.CSS_SELECTOR, \".pv\")  # .pv: 검색결과의 제목\n",
    "    date_elements = driver.find_elements(By.CSS_SELECTOR, \".past\")  # 날짜를 포함한 요소\n",
    "\n",
    "    for url_element, date_element in zip(url_elements, date_elements):\n",
    "        url = url_element.get_attribute('href')  # href(링크 주소) 속성값 가져오기\n",
    "        date = date_element.text  # 날짜 텍스트 가져오기\n",
    "\n",
    "        url_list.append(url)\n",
    "        date_list.append(date)\n",
    "\n",
    "    # 데이터프레임으로 저장\n",
    "    url_save = pd.DataFrame({\n",
    "        'keyword': [word] * len(url_list),\n",
    "        'url': url_list,\n",
    "        'date': date_list\n",
    "    })\n",
    "\n",
    "    file_path = os.path.join('url', '%s_url.csv' % word)\n",
    "    url_save.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fbffeb",
   "metadata": {
    "id": "58fbffeb"
   },
   "source": [
    "## Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc000adf",
   "metadata": {
    "id": "dc000adf"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import urllib.request # URL requests\n",
    "import urllib.parse # URL parsing\n",
    "\n",
    "import requests # HTTP requests\n",
    "from bs4 import BeautifulSoup as bs # HTML parsing\n",
    "\n",
    "from selenium import webdriver # Chromedriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By # HTML element 선택\n",
    "from selenium.webdriver.common.keys import Keys # 키보드 키 입력 위함\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities # 크롬 옵션 설정\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException # 예외 처리 위함\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException,\n",
    "    InvalidSessionIdException,\n",
    "    InvalidArgumentException,\n",
    "    TimeoutException,\n",
    "    WebDriverException,\n",
    "    StaleElementReferenceException\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9dbf58",
   "metadata": {
    "id": "bd9dbf58"
   },
   "outputs": [],
   "source": [
    "# 패턴\n",
    "pattern_2022_2023 = re.compile(r'^(2022|2023)\\.\\d{2}\\.\\d{2}\\.?$')\n",
    "pattern_2024 = re.compile(r'^2024\\.(01|02|03|04)\\.\\d{2}\\.?$')\n",
    "\n",
    "# 날짜 형식 확인 및 변환 함수\n",
    "def check_and_format_date(date_text):\n",
    "    # '작성시간' 한글 제거\n",
    "    date_text = date_text.replace('작성시간', '').strip()\n",
    "\n",
    "    # '분', '시간', '일'이 포함된 데이터 무시\n",
    "    if '분' in date_text or '시간' in date_text or '일' in date_text:\n",
    "        return None\n",
    "\n",
    "    # 'MM.DD' 형식의 데이터 처리\n",
    "    if re.match(r'^\\d{2}\\.\\d{2}$', date_text):\n",
    "        date_text = f\"2024.{date_text}\"\n",
    "\n",
    "    # 최종 날짜 형식 처리\n",
    "    if pattern_2022_2023.match(date_text) or pattern_2024.match(date_text):\n",
    "        return date_text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e854fa",
   "metadata": {
    "id": "54e854fa"
   },
   "outputs": [],
   "source": [
    "# 키워드\n",
    "keyword = ['반찬', '식습관']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cbad0",
   "metadata": {
    "id": "412cbad0",
    "outputId": "c0660548-d698-418c-b289-e92f6a511014"
   },
   "outputs": [],
   "source": [
    "# url 폴더 생성\n",
    "if not os.path.exists('url_data_processed'):\n",
    "    os.makedirs('url_data_processed')\n",
    "\n",
    "# 크롤링된 CSV 파일을 불러와서 전처리\n",
    "for word in keyword:\n",
    "    print('키워드:', word, '전처리 시작')\n",
    "\n",
    "    # 크롤링된 CSV 파일 불러오기\n",
    "    url_file_path = os.path.join('url', '%s_url.csv' % word)\n",
    "    data = pd.read_csv(url_file_path)\n",
    "\n",
    "    # 날짜 형식 확인 및 변환\n",
    "    data['date'] = data['date'].apply(check_and_format_date)\n",
    "\n",
    "    # None 값 제거 (날짜가 지정된 범위에 속하지 않는 데이터 제거)\n",
    "    data = data.dropna(subset=['date'])\n",
    "\n",
    "    # 데이터프레임을 CSV 파일로 저장\n",
    "    processed_file_path = os.path.join('url_data_processed', './%s_url_data_processed.csv' % word)\n",
    "    data.to_csv(processed_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fea53",
   "metadata": {
    "id": "3e1fea53"
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() # 크롬드라이버 객체 생성(초기화)\n",
    "driver.implicitly_wait(3) # 암묵적 대기(3초)\n",
    "\n",
    "url = 'https://www.teamblind.com/kr/'\n",
    "driver.get(url) # URL 접속\n",
    "\n",
    "# 이 셀까지 진행한 후 드라이버에 직접 로그인(인증번호) 필요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de4ce5",
   "metadata": {
    "id": "c4de4ce5"
   },
   "outputs": [],
   "source": [
    "# url 폴더 생성\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4702a",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "33b591500f94473db5c35123163796b0"
     ]
    },
    "id": "0ed4702a",
    "outputId": "40c228b8-9c54-4750-943e-691e421db745"
   },
   "outputs": [],
   "source": [
    "# 크롤링 시작\n",
    "for word in keyword:\n",
    "    print('키워드:', word, '크롤링 시작')\n",
    "\n",
    "    # url_csv 불러오기\n",
    "    processed_file_path = os.path.join('url_data_processed', f'{word}_url_data_processed.csv')\n",
    "    url_list = pd.read_csv(processed_file_path)\n",
    "\n",
    "    # 크롤링 결과 저장할 리스트 생성\n",
    "    pre_board_list = []\n",
    "    post_board_list = []\n",
    "    title_list = []\n",
    "    date_list = []\n",
    "    content_list = []\n",
    "    review_list = []\n",
    "    keyword_list = []\n",
    "\n",
    "    # url_list 크롤링\n",
    "    for url in tqdm(url_list['url']):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            driver.implicitly_wait(3)\n",
    "            time.sleep(random.uniform(1, 1.7))\n",
    "\n",
    "            # 날짜 추출\n",
    "            formatted_date = url_list[url_list['url'] == url]['date']\n",
    "\n",
    "            # 게시판 이름 추출\n",
    "            pre_board = driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[2]/div[1]/h1/a[1]')\n",
    "            pre_board_text = pre_board.text\n",
    "\n",
    "            try:\n",
    "                post_board = driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[2]/div[1]/h1/a[2]')\n",
    "                post_board_text = post_board.text\n",
    "            except NoSuchElementException:\n",
    "                post_board_text = None\n",
    "\n",
    "            # 제목 추출\n",
    "            title = driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[2]/div[1]/h2')\n",
    "            title_text = title.text\n",
    "\n",
    "            # 본문 추출\n",
    "            content = driver.find_element(By.XPATH, '//*[@id=\"contentArea\"]')\n",
    "            content_text = content.text\n",
    "\n",
    "            # 댓글 버튼 클릭\n",
    "            try:\n",
    "                if driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[2]/div[4]/button'):\n",
    "                    while True:\n",
    "                        driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[1]/div[4]/button').click()\n",
    "                        time.sleep(0.5)\n",
    "                        if not driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[1]/div[4]/button'):\n",
    "                            break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # 대댓글 더보기 클릭\n",
    "            try:\n",
    "                if driver.find_element(By.CSS_SELECTOR, '.btn-reply'):\n",
    "                    re = 0\n",
    "                    while True:\n",
    "                        re += 1\n",
    "                        driver.find_element(By.CSS_SELECTOR, '.btn-reply').click()\n",
    "                        time.sleep(0.5)\n",
    "                        if not driver.find_element(By.CSS_SELECTOR, '.btn-reply') or re == 20:\n",
    "                            break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # 댓글 추출\n",
    "            review_text = ''\n",
    "            reviews = driver.find_elements(By.CSS_SELECTOR, '.cmt-txt')\n",
    "            for review in reviews:\n",
    "                try:\n",
    "                    review_content = review.text\n",
    "                    if review_content != '작성자가 삭제한 댓글입니다.':\n",
    "                        review_text += ' ' + review_content\n",
    "                except StaleElementReferenceException:\n",
    "                    reviews = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.cmt-txt')))\n",
    "\n",
    "            # 리스트에 추가\n",
    "            pre_board_list.append(pre_board_text)\n",
    "            post_board_list.append(post_board_text)\n",
    "            title_list.append(title_text)\n",
    "            date_list.append(formatted_date)\n",
    "            content_list.append(content_text)\n",
    "            review_list.append(review_text)\n",
    "            keyword_list.append(word)\n",
    "\n",
    "        except (InvalidSessionIdException, InvalidArgumentException, WebDriverException, NoSuchElementException) as e:\n",
    "            print(f\"Invalid URL: {url}\")\n",
    "            continue\n",
    "\n",
    "    # 데이터프레임 생성 및 CSV 저장\n",
    "    data = pd.DataFrame({\n",
    "        '키워드': keyword_list,\n",
    "        '게시판_대분류': pre_board_list,\n",
    "        '게시판_소분류': post_board_list,\n",
    "        '제목': title_list,\n",
    "        '날짜': date_list,\n",
    "        '본문': content_list,\n",
    "        '댓글': review_list\n",
    "    })\n",
    "\n",
    "    file_path = os.path.join('data', f'{word}_data.csv')\n",
    "    data.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
